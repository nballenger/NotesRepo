<!DOCTYPE html>
<html>
<head>
<style type="text/css">
td pre { border: 1px solid #333333; padding: 10px; }
table table th { color: #666666; font-weight: normal; font-style: italic; }
</style>
</head>
<body>

<section>
  <header>
    <h1>Descriptive Statistics</h1>
  </header>

<table>
  <thead></thead>
  <tbody>
    <tr>
      <th scope="row">Mean</th>
      <td>
        <table>
          <tr>
            <th scope="col">Population</th>
            <th scope="col">Sample</th>
            <th scope="col">Weighted</th>
            <th scope="col">Properties</th>
          </tr>
          <tr>
            <td>
<pre>
    &Sum;<i>X<sub>i</sub></i>
<i>&mu;</i> = ---
     <i>N</i>
</pre>
            </td>
            <td>
<pre>
_   &Sum;<i>X<sub>i</sub></i>
<i>X</i> = ---
     <i>n</i>
</pre>
            </td>
            <td>
<pre>
_    &Sum;<i>X<sub>i</sub>w<sub>i</sub></i>
<i>X<sub>w</sub></i> = -----
      &Sum;<i>w<sub>i</sub></i>
</pre>
            </td>
            <td>
              <ol>
                <li>The mean always exists.</li>
                <li>The mean is unique.</li>
                <li>The mean is affected by outliers.</li>
                <li>The mean is "relatively reliable"; it does not vary widely on repeated sampling from the same population.</li>
            </td>
          </tr>
        </table>
      </td>
    </tr>
    <tr>
      <th scope="row">Median</th>
      <td>
        <table>
          <tr>
            <th scope="col">Method</th>
            <th scope="col">Properties</th>
          </tr>
          <tr>
            <td>
              <ol>
                <li>Arrange observations on variable X in increasing sequence.</li>
                <li>
                  <ol>
                    <li>If N is odd, median is the middle term.</li>
                    <li>If N is even, median is average of two middle terms.</li>
                  </ol>
                </li>
              </ol>
            </td>
            <td>
              <ol>
                <li>The median may or may not equal the mean.</li>
                <li>The median always exists.</li>
                <li>The median is unique.</li>
                <li>The median is not affected by outliers.</li>
              </ol>
            </td>
          </tr>
        </table>
      </td>
    </tr>
    <tr>
      <th scope="row">Mode</th>
      <td>
        <table>
          <tr>
            <th scope="col">Method</th>
            <th scope="col">Properties</th>
          </tr>
          <tr>
            <td>
              Count frequencies of all values of X. The most frequent value(s) are the mode(s). If no value is more frequent than any other, there is no mode.
            </td>
            <td>
              <ol>
                <li>The mode may or may not equal the mean and median.</li>
                <li>The mode may not exist.</li>
                <li>If the mode exists, it may not be unique.</li>
                <li>The mode is not affected by outliers.</li>
                <li>The mode always corresponds to an actual value of <i>X</i>.</li>
              </ol>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </tbody>
  <tfoot></tfoot>
</table>

</section>

<section>
  <header>
    <h1>Probability</h1>
  </header>
<table>
  <tr>
    <td>General</td>
    <td>
<pre>
P{&Omega;} = 1             P{&emptyset;} = 0

P{E} =    &Sum; P{&omega;<sub>k</sub>}
       &omega;<sub>k</sub> &Element; E
</pre>
    </td>
  </tr>
  <tr>
    <td>Union/Intersection</td>
    <td>
<pre>
P{A<sup>C</sup>} = 1 - P{A}

P{A &Union; B} = P{A} + P{B} - P{A &Intersection; B}

Independent: P{A &Intersection; B} = P{A} * P{B}

General:     P{A &Intersection; B} = P{B} * P{A | B}

P{A &Union; B &Union; C} = P{A} + P{B} + P{C}
                - P{A &Intersection; B} - P{B &Intersection; C} - P{A &Intersection; C}
                + P{A &Intersection; B &Intersection; C}

P{E<sub>1</sub> &Intersection; E<sub>2</sub> &Intersection; ... &Intersection; E<sub>n</sub> = P{E<sub>1</sub>} * P{E<sub>2</sub>} * ... * P{E<sub>n</sub>}
</pre>
    </td>
  </tr>
  <tr>
    <td>Combinatorics</td>
    <td>
<pre>
P<sub>r</sub> = PermuteWithReplacement(n,k) = n<sup>k</sup>

                                  n!
P = PermuteWOReplacement(n,k) = &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
                                (n-k)!

                                   (k+n-1)!
C<sub>r</sub> = CombineWithReplacement(n,k) = &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
                                   k!(n-1)!

                                   n!
C = CombineWOReplacement(n,k) = &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
                                k!(n-k)!

                                                   n!
Partition(n,partSize1,partSize2,...) = &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
                                       partSize1!*partSize2!*...
</pre>
    </td>
  </tr>
  <tr>
    <td>Conditional</td>
    <td>
<pre>

           P{A &Intersection; B}
P{A | B} = --------
             P{B}

                  P{A | B} * P{B}
Bayes: P{B | A} = ---------------
                        P{A}
</pre>
    </td>
  </tr>
  <tr>
    <td>Total Probability</td>
    <td>
<pre>
        k
P{A} =  &Sum; P{A | B<sub>j</sub>} * P{B<sub>j</sub>}
       j=1

if k = 2:  P{A} = P{A | B} * P{B} + P{A | B<sup>C</sup>} * P{B<sup>C</sup>}

                                   P{A | B} * P{B}
Bayes for k=2: P{B | A} = -----------------------------------
                          P{A | B} * P{B} + P{A | B<sup>C</sup>} * P{B<sup>C</sup>}
</pre>
    </td>
  </tr>
  <tr>
    <td>Distribution of a<br>Random Variable</td>
    <td>
<pre>
P(x) = P{X = x}  &larr; probability mass function

F(x) = P{X &le; x} = &Sum; P(y)   &larr; cumulative distribution function
                 <small>y&le;x</small>
</pre>
    </td>
  </tr>
  <tr>
    <td>Distribution of a<br>Random Vector</td>
    <td>
<pre>
P(x,y) = P{(X,Y)=(x,y)} = P{X = x &Intersection; Y = y} &larr; joint pmf of X,Y

P<sub>X</sub>(x) = P{X = x} = &Sum; P<sub>(X,Y)</sub>(x,y)
                   <sup>y</sup>

P<sub>Y</sub>(y) = P{Y = y} = &Sum; P<sub>(X,Y)</sub>(x,y)
                   <sup>x</sup>
</pre>
    </td>
  </tr>
  <tr>
    <td>Independence of<br>Random Variables</td>
    <td>
<pre>
Variables X and Y are independent iff:

P<sub>(X,Y)</sub>(x,y) = P<sub>X</sub>(x) * P<sub>Y</sub>(y)
</pre>
    </td>
  </tr>
  <tr>
    <td>Expectation</td>
    <td>
<pre>
&mu; = E(X) = &Sum; xP(x) &larr; expectation, discrete case
           <sup>x</sup>

E{g(X)} = &Sum; g(x)P(x) &larr; expectation of a function
          <sup>x</sup>

Properties of Expectations:

  E(aX + bY + c) = aE(X) + bE(Y) + c

  E(X+Y) = E(X) + E(Y)
  E(aX)  = aE(X)
  E(c)   = c

  E(XY) = E(X)E(Y)  &larr; independent X and Y

</pre>
    </td>
  </tr>
  <tr>
    <td>Variance</td>
    <td>
<pre>
</pre>
    </td>
  </tr>
</table>
</section>
</body>
</html>
