# Notes on Docker for Rails Developers

By Rob Isenberg; Pragmatic Bookshelf, Feb. 2019; ISBN 9781680502732

# Chapter 1: A Brave New World

# Chapter 2: Running a Rails App in a Container

Base rails container:

```
FROM ruby:2.6

RUN apt-get update -yqq \
 && apt-get install -yqq --no-install-recommends nodejs

COPY . /usr/src/app

WORKDIR /usr/src/app

RUN bundle install
```

Running a rails server off the image:

```bash
docker run -p 3000:3000 my_rails:latest bin/rails s -b 0.0.0.0
```

# Chapter 3: Fine-Tuning Our Rails Image

* Adds a CMD: `CMD ["bin/rails", "s", "-b", "0.0.0.0"]`
* Adds a .dockerignore

## The Gemfile Caching Trick

* Separate the copying of files that should trigger a rebuild of your gems from those that should not.
* If you copy in your Gemfile and Gemfile.lock independently prior to running `bundle install`, you get that done on a separate layer

# Chapter 4: Describing our App Declaratively with Docker Compose

Docker compose file:

```YAML
version: '3'

services:
  web:
    build: .
    ports:
      - "3000:3000"
    volumes:
      - .:/usr/src/app
```

By default, Ruby buffers output to stdout, and Docker Compose doesn't work well with that. Switch off ruby buffering by adding this to the top of `config/boot.rb`: `$stdout.sync = true`

# Chapter 5: Beyond the App: Adding Redis

Add a new service to the docker compose file:

```YAML
services:
  [...]
  redis:
    image: redis
```

To get the app talking to the redis container:

* Install the `redis` gem by adding it to the Gemfile and rebuilding
* Generate a welcome controller in the Rails app: `docker-compose exec web bin/rails g controller welcome index`
* Modify the index action in `app/controllers/welcome_controller.rb` to be:

    ```Ruby
    class WelcomeController < ApplicationController
        def index
            redis = Redis.new(host: "redis", port: 6379)
            redis.incr "page hits"

            @page_hits = redis.get "page hits"
        end
    end
    ```

* Edit the view file at `app/views/welcome/index.html.erb`:

    ```
    <h1>Page viewed <%= pluralize(@page_hits, 'time') %>!</h1>
    ```

* Edit `config/routes.rb` to update the autogenerated route so you can access the WelcomeController's index action from `/welcome` rather than `/welcome/index`:

    ```Ruby
    Rails.application.routes.draw do
        get 'welcome', to: 'welcome#index'
    end
    ```

# Chapter 6: Adding a Database: Postgres

Docker compose file additions:

```
services:
  web:
    [...]
    env_file:
      - .env/development/database
      - .env/development/web

  database:
    image: postgres
    env_file:
      - .env/development/database
    volumes:
      - db_data:/var/lib/postgresql/data

volumes:
  db_data:
```

To connect the app container, in the Gemfile replace `gem 'sqlite3'` with `gem 'pg','~> 1.0'`, then rebuild the app container image.

In `config/database.yml`, replace the contents with:

```YAML
default: &default
  adapter: postgresql
  encoding: unicode
  host: <%= ENV.fetch('DATABASE_HOST') %>
  username: <%= ENV.fetch('POSTGRES_USER') %>
  password: <%= ENV.fetch(POSTGRES_PASSWORD') %>
  database: <%= ENV.fetch('POSTGRES_DB') %>
  pool: 5
  variables:
    statement_timeout: 5000

development:
  <<: *default

test:
  <<: *default
  database: myapp_test

production:
  <<: *default
```

Make directories to store env specific config:

```bash
mkdir -p .env/development
echo "DATABASE_HOST=database" > .env/development/web
echo "POSTGRES_USER=postgres" > .env/development/database
echo "POSTGRES_PASSWORD=some_password" >> .env/development/database
echo "POSTGRES_DB=myapp_development" >> .env/development/database
```

Then create the database:

```bash
docker-compose run --rm web bin/rails db:create
```

Because Compose will reuse existing containers for a server, you have to tell it to recreate the web container:

```bash
docker-compose up -d --force-recreate web
```

To actually use the database in practice, you generate a scaffold, then run the migrations to create the Users table:

```bash
docker-compose exec web bin/rails g scaffold User first_name:string last_name:string
docker-compose exec web bin/rails db:migrate
```

If you put the database into a docker volume, you need to mount the volume while recreating the database container:

```bash
docker-compose stop database
docker-compose rm -f database
docker-compose up -d database
docker-compose exec web bin/rails db:create db:migrate
```

# Chapter 7: Playing Nice with JavaScript

* Rails includes Webpacker, which is a gem that brings in `webpack` support
* Chapter explores options for including JS as part of Rails deployment
* Biggest choice about a JS front end is whether Rails will serve it
* If not, you use the Rails app as a API layer with a separate front end
* Doing that is outside the book's scope, but basically looks like:
    1. Rename the `web` service to reflect that it's an api service
    1. Create a custom image to run the front end app
    1. Create a separate service in the docker-compose file to support the standalone JS application. Make sure to configure the API endpoint(s) it should use for the Rails api service.
* If you use Rails to serve the front end, you should use the facilities native to Rails. Two ways to do that: asset pipeline or Webpacker
* Assets pipeline is bases on Sprockets, and works out of the box. When runnign the rails server, your assets are compiled and served up in views in a standard way.
* To use Webpacker with Docker takes a bit more work.
* Webpacker has a modular architecture, so it can work with different frameworks
* Updating the docker file:

    ```Docker
    FROM ruby:2.6

    # Allow apt to work with https-based sources
    RUN apt-get update -yqq \
     && apt-get install -yqq --no-install-recommends apt-transport-https

    # Install up to date version of Node
    RUN curl -sL https://deb.nodesource.com/setup_8.x | bash -

    # Ensure latest packages for Yarn
    RUN curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add -
    RUN echo "deb https://dl.yarnpkg.com/debian/ stable main" | \
        tee /etc/apt/sources.list.d/yarn.list

    # Install packages
    RUN apt-get update -yqq \
     && apt-get install -yqq --no-install-recommends nodejs yarn

    COPY Gemfile* /usr/src/app
    WORKDIR /usr/src/app
    RUN bundle install

    COPY . /usr/src/app/

    CMD ["bin/rails", "s", "-b", "0.0.0.0"]
    ```

* If we were creating a new app, we could have included webpack support with `rails new myapp --webpack=react ...`
* Having already generated the app, adding webpack support involves manual steps.
* Add to the Gemfile: `gem 'webpacker','~> 3.5'`
* Run `docker-compose build web`
* Stop the web service: `docker-compose stop web`
* Install it `docker-compose run web bin/rails webpacker:install`
* Add the react integration: `docker-compose run web bin/rails webpacker:install:react`
* Rails provides `webpack-dev-server` as a binary, which is a small server that runs in the background and automatically compiles webpack managed files. In docker you can run this as a separate service:

    ```YAML
    services:
      [...]

      webpack_dev_server:
        build: .
        command: ./bin/webpack-dev-server
        ports:
          - "3035:3035"
        volumes:
          - .:/usr/src/app
        env_file:
          - .env/development/web
          - .env/development/database
        environment:
          - WEBPACKER_DEV_SERVER_HOST=0.0.0.0
    ```

* Mounting the local files to the container means they'll be managed by Webpacker as a watcher.
* Restart the web service to pick up the config changes, and launch the new service:

    ```
    docker-compose up -d web
    docker-compose up -d webpack_dev_server
    ```

# Chapter 8: Testing in a Dockerized Environment

* Chapter sets up the RSpec testing framework
* Add the following to the Gemfile:

    ```Ruby
    group :development, :test do
        # Call 'byebug' anywhere to stop execution and get a debugger
        gem 'byebug', platforms: [:mri, :mingw, :x64_mingw]
        gem 'rspec-rails','~> 3.8'
    end
    ```

* Stop the web service: `docker-compose stop web`
* Rebuild the image to run bundle install and create a new container from it:

    ```
    docker-compose build web
    docker-compose up -d --force-recreate web
    
    # install Rspec, which sets up its file structure
    docker-compose exec web bin/rails generate rspec:install

    # Run the specs
    docker-compose exec web bin/rails spec

    # Generate a spec for the User model
    docker-compose exec web bin/rails generate rspec:model user
    ```

* Now edit the newly created `spec/models/user_spec.rb` file:

    ```Ruby
    require 'rails_helper'

    RSpec.describe User do
      describe "validations" do
        it "requires first_name to be set" do
          expect(subject.valid?).to_not be
          expect(subject.errors[:first_name].size).to eq(1)
        end

        it "requires last_name to be set" do
          expect(subject.valid?).to_not be
          expect(subject.errors[:last_name].size).to eq(1)
        end
      end
    end
    ```

* Running the tests again produces failures because there's no validation on teh User model
* Update the user model in `app/models/user.rb`:

    ```Ruby
    class User < ApplicationRecord
      validates_presence_of :first_name, :last_name
    end
    ```

* Rails system tests were added in 5.1, and let you do high level, end to end tests of an application. The assertions are for user interaction events and app responses.

# Chapter 9: Advanced Gem Management

* There's a downside to using bundler to install the gems as a step in teh Dockerfile
* Given the way it's set up above, adding a gem forces a reinstall of all gems, so the update time for the container build is long
* The fix is to use a Gem cache volume. Mounting a volume to the directory where Bundler installs the gems means you can execute Bundler commands to manage the gems on the volume, which then becomes a local gem cache.
* If you set `BUNDLE_PATH` in the env, that sets the base path for bundle installs
* Dockerfile:

    ```Docker
    [...]
    COPY Gemfile * /usr/src/app
    WORKDIR /usr/src/app

    ENV BUNDLE_PATH /gems

    RUN bundle install

    COPY . /usr/src/app/

    CMD ["bin/rails", "s", "-b", "0.0.0.0"]
    ```

* Docker compose file:

    ```YAML
    version: '3'

    services:
      web:
        build: .
        ports:
          - "3000:3000"
          - "4000:4000"
        volumes:
          - .:/usr/src/app
          - gem_cache:/gems
        env_file:
          - .env/development/web
          - .env/development/database
        environment:
          - WEBPACKER_DEV_SERVER_HOST=webpack_dev_server

      webpack_dev_server:
        build: .
        command: ./bin/webpack_dev_server
        ports:
          - "3035:3035"
        volumes:
          - .:/usr/src/app
          - gem_cache:/gems
        env_file:
          - .env/development/web
          - .env/development/database
        environment:
          - WEBPACKER_DEV_SERVER_HOST=0.0.0.0

      redis:
        image: redis

      database:
        image: postgres
        env_file:
          - .env/development/database
        volumes:
          - db_data:/var/lib/postgresql/data

      selenium_chrome:
        image: selenium/standalone-chrome-debug
        logging:
          driver: none
        ports:
          - "5900:5900"

    volumes:
      db_data:
      gem_cache:
    ```

* Rebuild the web service image, create a new container, then run bundle install against it:

    ```bash
    docker-compose build web
    docker-compose up -d web
    docker-compose exec web bundle install
    ```

# Chapter 10: Some Minor Irritations

## PID file not cleaned up

* Sometimes, terminating the app via compose with ctrl-c produces a non-graceful exit for the rails server, which means `tmp/pids/server.pid` doesn't get cleaned up, making a restart not work.
* If that happens, simply delete the pid file. Alternately, create a `docker-entrypoint.sh` script in your Rails root:

    ```sh
    #!/bin/sh

    set -e

    if [-f tmp/pids/server.pid]; then
      rm tmp/pids/server.pid
    fi

    exec "$@"
    ```

* Chmod that to executable, then use it as the ENTRYPOINT script

## Compose aborts on ctrl-c

* If you start your app without `-d` for detached mode (and therefore are in attached mode), Compose tails the output of each attached container's stdout
* On ctrl-c, Compose *should* send SIGTERM to the main process of each container. The process should exit gracefully and then the container should terminate.
* Some of the time that doesn't happen. It's a known issue, seems related to PyInstaller, which Compose uses. You can use `docker-compose stop` or `kill` to stop the containers manually.
* If you're affected, use detached mode

# Closing Thoughts on Docker in Development

* Benefits:
    * Declarative description of entire application
    * Single command to stand up / tear down the app
    * Eliminates the need to use your local machine for dependencies directly
    * Creates a portable container
    * Upgrading parts of the application is as simple as upgrading the version number of the image you refer to in your Compose file

# Chapter 11: The Production Landscape

* Areas of Ops responsibility:
    * Provisioning - creating the compute, network, storage resources
    * Config management - installation, configuration
    * Release management - deployment pipelines
    * Monitoring and alerting - telemetry
    * Operating - scaling, troubleshooting, process management
* Container orchestration
    * Container registries solve the problem of getting software onto machines
    * Containerization lets you treat units of software as interchangeable
    * Orchestrating containers requires orchestration management tooling
    * That creates a platform for running/managing apps / services
    * Helpful to think of deploying groups of compute resources as clusters
    * Orchestrators are typically declarative, so you tell them the desired state and they bring the cluster(s) to that state.
    * Orchestrators can also do secret management
    * They tend to have security features like key rotation built in
* Swarm and Kubernetes orchestrators
    * Swarm
        * Built into the docker engine since 1.12
        * Currently production ready
    * Kubernetes
        * open source tool, built by Google, now under care of Cloud Native Computing Foundation
        * Supports autoscaling, gives you control over how apps are architected
        * Much more complex than Swarm, longer learning curve, more verbose configuration
    * Both are similarly architected at a high level
        * Both have worker nodes that run containers, and manager nodes that manage workers and orchestrate containers on them.
        * Swarm manager nodes can run workload containers in addition to their cluster management, k8s manager nodes can't
    * Some hosting providers have their own orchestration, like ECS on AWS
* IaaS vs. CaaS
    * Infrastructure as a service means you manage the underlying resources
    * Containers as a service means typically you don't

## Provisioning your infrastructure

* If you go with IaaS, you'll work in a cloud platform like AWS, Azure, etc.
* Tools that help with this:
    * Docker Machine - standalone tool for provisioning and managing Docker-ready instances.
    * Chef, Puppet, Ansible - config management tools, need them less, but can be used to bootstrap Docker onto machines that will run containers.
    * Terraform - an 'infrastructure orchestrator', aims to provision and update infrastructure in a safe, controlled way. Popular adjunct to Docker.

## CaaS Platforms

* Kubernetes tends to be the biggest tool in this space.
* Once your workload cluster is up, you interact with it via `kubectl`
* AWS ECS
    * Elastic Container Service is AWS's own orchestration layer
    * has very fine grained control, but you have to manage additional complexity and do more interconnection work
* Google Kubernetes Engine
    * GKE lets you entirely forget about the underlying hardware
    * Seems to be most mature, user-friendly offering in the space
* AWS ECS for Kubernetes
    * EKS has some AWS leak-through--since it needs to be able to create EC2 instances on your behalf, you have to deal with IAM service roles.
    * tends to work out pricier than the other offerings
* Azure Kubernetes Service
    * Solid, but runner up to GKE in terms of features, ease of use

## Serverless for Containers


